{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00fad453",
      "metadata": {
        "id": "00fad453"
      },
      "source": [
        "# Домашнее задание № 4. Языковые модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d056af4",
      "metadata": {
        "id": "5d056af4"
      },
      "source": [
        "## Задание 1 (8 баллов)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f532a8",
      "metadata": {
        "id": "d1f532a8"
      },
      "source": [
        "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de743d1d",
      "metadata": {
        "id": "de743d1d"
      },
      "source": [
        "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
        "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели.\n",
        "Можно использовать данные из семинара или любые другие (можно брать только часть текста, если считается слишком долго). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
        "\n",
        "\n",
        "Подсказки:  \n",
        "    - нужно будет добавить еще один тэг \\<start>  \n",
        "    - можете использовать тот же подход с матрицей вероятностей, но по строкам хронить биграмы, а по колонкам униграммы\n",
        "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)\n",
        "    - у вас будут словари с индексами биграммов и униграммов, не перепутайте их при переводе индекса в слово - словарь биграммов будет больше словаря униграммов и все индексы из униграммного словаря будут формально подходить для словаря биграммов (не будет ошибки при id2bigram[unigram_id]), но маппинг при этом будет совершенно неправильным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d078056d",
      "metadata": {
        "id": "d078056d",
        "outputId": "7e8f865c-1b64-4d79-fe4b-09a744f1c9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6afcef88",
      "metadata": {
        "id": "6afcef88"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Добавляет тэги <start> и токенизирует текст.\"\"\"\n",
        "    sentences = text.lower().split('.')\n",
        "    tokenized_sentences = [['<start>', '<start>'] + sent.strip().split() + ['<end>'] for sent in sentences if sent]\n",
        "    return tokenized_sentences\n",
        "\n",
        "def build_ngram_counts(sentences, n=3):\n",
        "    \"\"\"Собирает статистику для n-грамм, биграмм и униграмм.\"\"\"\n",
        "    unigrams = Counter()\n",
        "    bigrams = Counter()\n",
        "    trigrams = Counter()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for i in range(len(sentence)):\n",
        "            unigrams[sentence[i]] += 1\n",
        "            if i >= 1:\n",
        "                bigrams[(sentence[i-1], sentence[i])] += 1\n",
        "            if i >= 2:\n",
        "                trigrams[(sentence[i-2], sentence[i-1], sentence[i])] += 1\n",
        "\n",
        "    return unigrams, bigrams, trigrams\n",
        "\n",
        "def calculate_trigram_probabilities(unigrams, bigrams, trigrams, vocab_size):\n",
        "    \"\"\"Рассчитывает вероятности P(word | word1, word2) с учетом сглаживания.\"\"\"\n",
        "    probabilities = defaultdict(float)\n",
        "\n",
        "    for (word1, word2, word3), trigram_count in trigrams.items():\n",
        "        bigram_count = bigrams[(word1, word2)]\n",
        "        probabilities[(word1, word2, word3)] = (trigram_count + 1) / (bigram_count + vocab_size)\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "def generate_text(trigram_probs, unigrams, n=20):\n",
        "    \"\"\"Генерирует текст с использованием треграммной модели.\"\"\"\n",
        "    text = ['<start>', '<start>']\n",
        "    vocab = list(unigrams.keys())\n",
        "\n",
        "    for _ in range(n):\n",
        "        prev_bigram = (text[-2], text[-1])\n",
        "        candidates = {word3: prob for (word1, word2, word3), prob in trigram_probs.items() if (word1, word2) == prev_bigram}\n",
        "        if candidates:\n",
        "            next_word = random.choices(list(candidates.keys()), weights=list(candidates.values()))[0]\n",
        "        else:\n",
        "            next_word = random.choice(vocab)\n",
        "        if next_word == '<end>':\n",
        "            break\n",
        "        text.append(next_word)\n",
        "\n",
        "    return ' '.join(text[2:])\n",
        "\n",
        "def calculate_perplexity(test_sentences, trigram_probs, bigrams, vocab_size):\n",
        "    \"\"\"Вычисляет перплексию для тестового множества.\"\"\"\n",
        "    log_prob_sum = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for sentence in test_sentences:\n",
        "        for i in range(2, len(sentence)):\n",
        "            trigram = (sentence[i-2], sentence[i-1], sentence[i])\n",
        "            bigram = (sentence[i-2], sentence[i-1])\n",
        "            trigram_prob = trigram_probs.get(trigram, 1 / (bigrams[bigram] + vocab_size))\n",
        "            log_prob_sum += -np.log2(trigram_prob)\n",
        "            total_words += 1\n",
        "\n",
        "    return 2 ** (log_prob_sum / total_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Текстовый корпус\n",
        "text = \"\"\"\n",
        "I love natural language processing. It is fascinating to work with text data.\n",
        "Language modeling is an essential part of NLP. Deep learning models are also great for text analytics.\n",
        "\"\"\"\n",
        "\n",
        "sentences = preprocess_text(text)\n",
        "\n",
        "unigrams, bigrams, trigrams = build_ngram_counts(sentences)\n",
        "vocab_size = len(unigrams)\n",
        "\n",
        "trigram_probs = calculate_trigram_probabilities(unigrams, bigrams, trigrams, vocab_size)\n",
        "\n",
        "# Генерация текста\n",
        "for _ in range(5):\n",
        "    print(\"Generated text:\", generate_text(trigram_probs, unigrams))\n",
        "\n",
        "# Тестовое множество для перплексии\n",
        "test_sentences = preprocess_text(\"Text analysis is fun. I enjoy working on NLP tasks.\")\n",
        "perplexity = calculate_perplexity(test_sentences, trigram_probs, bigrams, vocab_size)\n",
        "print(\"Perplexity:\", perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_cgcPkPL0qm",
        "outputId": "e0e491d9-5892-47ed-e822-1fa92ca0f362"
      },
      "id": "N_cgcPkPL0qm",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: language modeling is an essential part of nlp\n",
            "Generated text: language modeling is an essential part of nlp\n",
            "Generated text: deep learning models are also great for text analytics\n",
            "Generated text: language modeling is an essential part of nlp\n",
            "Generated text: i love natural language processing\n",
            "Perplexity: 28.187242351121117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e0a8dd5",
      "metadata": {
        "id": "8e0a8dd5"
      },
      "source": [
        "## Задание № 2* (2 балла)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f733858c",
      "metadata": {
        "id": "f733858c"
      },
      "source": [
        "Измените функцию generate_with_beam_search так, чтобы она работала с моделью, которая учитывает два предыдущих слова.\n",
        "Сравните получаемый результат с первым заданием.\n",
        "Также попробуйте начинать генерацию не с нуля (подавая \\<start> \\<start>), а с какого-то промпта. Но помните, что учитываться будут только два последних слова, так что не делайте длинные промпты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c426746a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c426746a",
        "outputId": "a24a0e6e-e63f-4adb-c13e-24620f8fec3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated with default start:\n",
            "it is fascinating to work with text data language work nlp fascinating nlp i fascinating text processing processing natural\n",
            "\n",
            "Generated with prompt 'language is':\n",
            "language is to essential for models love an for fascinating language natural is is fascinating to work with text data\n",
            "\n",
            "Generated with prompt 'deep learning':\n",
            "deep learning models are also great for text analytics\n"
          ]
        }
      ],
      "source": [
        "def generate_with_beam_search(trigram_probs, unigrams, prompt=None, beam_width=3, max_len=20):\n",
        "    \"\"\"\n",
        "    Генерация текста с использованием бим-сьёрча (beam search) для треграммной языковой модели.\n",
        "\n",
        "    Параметры:\n",
        "        trigram_probs (dict): вероятности триграмм P(word | word1, word2).\n",
        "        unigrams (Counter): частоты униграмм для выбора случайных слов.\n",
        "        prompt (list or None): начальный промпт для генерации (например, ['<start>', '<start>']).\n",
        "        beam_width (int): ширина луча beam search.\n",
        "        max_len (int): максимальная длина генерируемого текста.\n",
        "\n",
        "    Возвращает:\n",
        "        generated_text (str): сгенерированный текст.\n",
        "    \"\"\"\n",
        "    if prompt is None:\n",
        "        prompt = ['<start>', '<start>']  # Если промпт не задан, начинаем с тэгов <start>\n",
        "    else:\n",
        "        # Если промпт короче двух слов, добавляем <start>\n",
        "        prompt = ['<start>'] * (2 - len(prompt)) + prompt\n",
        "\n",
        "    # Начальные состояния луча\n",
        "    sequences = [(prompt, 0)]  # пары (последовательность, логарифмическая вероятность)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        all_candidates = []\n",
        "\n",
        "        # Для каждой последовательности в текущем биме расширяем возможные слова\n",
        "        for seq, score in sequences:\n",
        "            prev_bigram = (seq[-2], seq[-1])  # Два последних слова из последовательности\n",
        "            candidates = {word3: prob for (word1, word2, word3), prob in trigram_probs.items() if (word1, word2) == prev_bigram}\n",
        "\n",
        "            # Если нет возможных кандидатов (не встречается такой биграмма), случайный выбор\n",
        "            if not candidates:\n",
        "                candidates = {random.choice(list(unigrams.keys())): 1 / len(unigrams)}\n",
        "\n",
        "            # Для каждого кандидата создаем новый путь\n",
        "            for word, prob in candidates.items():\n",
        "                new_seq = seq + [word]  # Расширяем последовательность\n",
        "                new_score = score - np.log2(prob)  # Логарифмическая сумма вероятностей (минимизация отриц. лог)\n",
        "                all_candidates.append((new_seq, new_score))\n",
        "\n",
        "        # Сортируем кандидатов по вероятности (первым идут лучшие) и берем top-K\n",
        "        sequences = sorted(all_candidates, key=lambda x: x[1])[:beam_width]\n",
        "\n",
        "        # Если все последовательности заканчиваются на <end>, выходим\n",
        "        if all(seq[-1] == '<end>' for seq, _ in sequences):\n",
        "            break\n",
        "\n",
        "    # Возвращаем последовательность с наивысшей вероятностью\n",
        "    best_sequence = min(sequences, key=lambda x: x[1])[0]\n",
        "\n",
        "    # Убираем стартовые токены и токен <end>\n",
        "    return ' '.join(word for word in best_sequence if word not in ['<start>', '<end>'])\n",
        "\n",
        "text = \"\"\"\n",
        "I love natural language processing. It is fascinating to work with text data.\n",
        "Language modeling is an essential part of NLP. Deep learning models are also great for text analytics.\n",
        "\"\"\"\n",
        "sentences = preprocess_text(text)\n",
        "unigrams, bigrams, trigrams = build_ngram_counts(sentences)\n",
        "vocab_size = len(unigrams)\n",
        "trigram_probs = calculate_trigram_probabilities(unigrams, bigrams, trigrams, vocab_size)\n",
        "\n",
        "# Генерация текста с bим-сьёрч\n",
        "print(\"Generated with default start:\")\n",
        "print(generate_with_beam_search(trigram_probs, unigrams, prompt=['<start>', '<start>']))\n",
        "\n",
        "print(\"\\nGenerated with prompt 'language is':\")\n",
        "print(generate_with_beam_search(trigram_probs, unigrams, prompt=['language', 'is']))\n",
        "\n",
        "print(\"\\nGenerated with prompt 'deep learning':\")\n",
        "print(generate_with_beam_search(trigram_probs, unigrams, prompt=['deep', 'learning']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nySi4KH-9DNe"
      },
      "id": "nySi4KH-9DNe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}