{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca384d0-da9b-41bc-a902-ee069922c0c2",
   "metadata": {},
   "source": [
    "## Домашка \n",
    "\n",
    "### Задание 1 (8 баллов)\n",
    "Обучите модель с минимум 15 слоями, где у каждого слоя разные параметры (Dropout, Conv1d и Pooling, Dense считаются слоями, остальное нет, но их тоже можно использовать). Как минимум 4 слоя должны быть наложены друг на друга и как минимум 2 параллельных слоя (последовательности слоев). Должен быть хотя бы один слой каждого типа.\n",
    "\n",
    "При обучении используйте колбек для отслеживания лучшей модели. Ориентируйтесь на Recall@Precision меру. Качество модели не должно быть околонулевым. Если метрики не растут, то попробуйте пообучать подольше или перестроить саму сеть.\n",
    "\n",
    "Советы: Начните с небольших сетей и постепенно добавляйте, не пытайтесь сразу собрать все слои. Иногда кернел может крашиться просто так или из-за слишком больших матриц.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe8a452-47c8-40f9-bc19-e6d8d8e598ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06865e28-604e-41ab-8e1e-237c165c7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(\".,!?;:'\\\"()[]{}\") for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "data = pd.read_csv(\"lenta_40k.csv.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "917e8d6a-cf57-483c-ad1a-818d08fdff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for t in data.text:\n",
    "    vocab.update(preprocess(t))\n",
    "filtered = {w for w,c in vocab.items() if c > 30}\n",
    "\n",
    "word2id = {\"PAD\":0, \"UNK\":1}\n",
    "for w in sorted(filtered):\n",
    "    word2id[w] = len(word2id)\n",
    "id2word = {i:w for w,i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af37644c-3e50-4005-af55-d03455c5d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for t in data.text:\n",
    "    ids = [word2id.get(tok,1) for tok in preprocess(t)]\n",
    "    X.append(ids)\n",
    "MAX_LEN = int(np.median([len(x) for x in X]) + 30)\n",
    "X = [x[:MAX_LEN] + [0]*max(0, MAX_LEN-len(x)) for x in X]\n",
    "X = np.array(X, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb905cb-599d-40db-9b02-4097073725d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {l:i for i,l in enumerate(sorted(set(data.topic)))}\n",
    "y = np.array([label2id[l] for l in data.topic], dtype=int)\n",
    "num_classes = len(label2id)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05,\n",
    "                                                  stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46efc463-5744-4738-9980-1661c3758159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = TextDataset(X_train, y_train)\n",
    "val_ds   = TextDataset(X_val,   y_val)\n",
    "batch_size = 256\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "306d5563-ab63-4a36-ae72-c64bee99c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_precision(outputs, targets, threshold=0.8):\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    confidences, preds = probs.max(dim=1)\n",
    "    preds_binary = confidences >= threshold\n",
    "    tp = ((preds == targets) & preds_binary).sum().item()\n",
    "    fp = (preds_binary & (preds != targets)).sum().item()\n",
    "    fn = ((preds != targets) & ~preds_binary).sum().item()\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall    = tp / (tp + fn + 1e-8)\n",
    "    return recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ba47f2-c916-44b2-a1bf-e15ccdd76bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task1Model(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv1d(emb_dim, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv1d(emb_dim, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv1d(emb_dim, 32, kernel_size=7, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Conv1d(96, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(64, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(32*(MAX_LEN//2), 64)\n",
    "        self.dropout_fc = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(0,2,1)  # B x emb_dim x L\n",
    "        b1 = self.branch1(x)\n",
    "        b2 = self.branch2(x)\n",
    "        b3 = self.branch3(x)\n",
    "        concat = torch.cat([b1,b2,b3], dim=1)\n",
    "        out = self.stack(concat)\n",
    "        out = out.flatten(1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout_fc(out)\n",
    "        return self.fc2(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4444d8a5-d368-47b9-85bf-eb2abc295a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, val_dl, epochs=10):\n",
    "    model.to(device)\n",
    "    opt = Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_rec = 0.0\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        model.train()\n",
    "        for xb,yb in train_dl:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        recs, precs = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb,yb in val_dl:\n",
    "                xb,yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                r,p = recall_at_precision(out, yb, threshold=0.8)\n",
    "                recs.append(r); precs.append(p)\n",
    "        mean_rec, mean_prec = np.mean(recs), np.mean(precs)\n",
    "        print(f\"Epoch {epoch}: Recall@0.8Prec={mean_rec:.4f}, Precision={mean_prec:.4f}\")\n",
    "        if mean_rec > best_rec:\n",
    "            best_rec = mean_rec\n",
    "            torch.save(model.state_dict(), \"best_task1.pt\")\n",
    "            print(\"  -> Saved best model\")\n",
    "    print(f\"Best Recall@Precision: {best_rec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18bee8e-2ac0-4a2f-a98e-3f2d8ff0eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Recall@0.8Prec=0.0000, Precision=0.0000\n",
      "Epoch 2: Recall@0.8Prec=0.0695, Precision=0.9724\n",
      "  -> Saved best model\n",
      "Epoch 3: Recall@0.8Prec=0.1619, Precision=0.9702\n",
      "  -> Saved best model\n",
      "Epoch 4: Recall@0.8Prec=0.3600, Precision=0.9305\n",
      "  -> Saved best model\n",
      "Epoch 5: Recall@0.8Prec=0.4171, Precision=0.9292\n",
      "  -> Saved best model\n",
      "Epoch 6: Recall@0.8Prec=0.4871, Precision=0.9248\n",
      "  -> Saved best model\n",
      "Epoch 7: Recall@0.8Prec=0.5168, Precision=0.9085\n",
      "  -> Saved best model\n",
      "Epoch 8: Recall@0.8Prec=0.5274, Precision=0.9185\n",
      "  -> Saved best model\n",
      "Epoch 9: Recall@0.8Prec=0.5443, Precision=0.9216\n",
      "  -> Saved best model\n",
      "Epoch 10: Recall@0.8Prec=0.5659, Precision=0.9140\n",
      "  -> Saved best model\n",
      "Epoch 11: Recall@0.8Prec=0.6162, Precision=0.8882\n",
      "  -> Saved best model\n",
      "Epoch 12: Recall@0.8Prec=0.6385, Precision=0.8787\n",
      "  -> Saved best model\n",
      "Epoch 13: Recall@0.8Prec=0.6498, Precision=0.8748\n",
      "  -> Saved best model\n",
      "Epoch 14: Recall@0.8Prec=0.6618, Precision=0.8727\n",
      "  -> Saved best model\n",
      "Epoch 15: Recall@0.8Prec=0.6639, Precision=0.8790\n",
      "  -> Saved best model\n",
      "Best Recall@Precision: 0.6639\n"
     ]
    }
   ],
   "source": [
    "model1 = Task1Model(len(word2id), emb_dim=100, num_classes=num_classes)\n",
    "train_model(model1, train_dl, val_dl, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e5812-1045-4664-8901-f24f4ff53308",
   "metadata": {},
   "source": [
    "\n",
    "### Задание 2 (2 балла)\n",
    "Обучите нейросеть со сверточными слоями с архитектурой похожей на Unet - https://en.wikipedia.org/wiki/U-Net\n",
    "\n",
    "Не нужно воспроизводить все в точности, главное, чтобы было сокращение длины последовательности с помощью CNN, а затем обратное увеличение длины последовательности до изначальной с residual связями между промежуточными шагами с одинаковыми размерностями. \n",
    "Изменений размерности должно быть хотя бы 3 и соответственно residual связей тоже. \n",
    "\n",
    "Для повышения размерности используйте keras.layers.UpSampling1D\n",
    "Полученная модель должна давать ненулевое качество на той же самой задаче классификации текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f23f0862-6117-4ba6-9f82-37c6a315af33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Recall@0.8Prec=0.0643, Precision=1.0000\n",
      "  -> Saved best model\n",
      "Epoch 2: Recall@0.8Prec=0.2509, Precision=0.9321\n",
      "  -> Saved best model\n",
      "Epoch 3: Recall@0.8Prec=0.4075, Precision=0.8979\n",
      "  -> Saved best model\n",
      "Epoch 4: Recall@0.8Prec=0.5131, Precision=0.9086\n",
      "  -> Saved best model\n",
      "Epoch 5: Recall@0.8Prec=0.5969, Precision=0.8830\n",
      "  -> Saved best model\n",
      "Epoch 6: Recall@0.8Prec=0.6214, Precision=0.8703\n",
      "  -> Saved best model\n",
      "Epoch 7: Recall@0.8Prec=0.6594, Precision=0.8674\n",
      "  -> Saved best model\n",
      "Epoch 8: Recall@0.8Prec=0.6797, Precision=0.8491\n",
      "  -> Saved best model\n",
      "Epoch 9: Recall@0.8Prec=0.7163, Precision=0.8170\n",
      "  -> Saved best model\n",
      "Epoch 10: Recall@0.8Prec=0.7342, Precision=0.8147\n",
      "  -> Saved best model\n",
      "Epoch 11: Recall@0.8Prec=0.7547, Precision=0.7902\n",
      "  -> Saved best model\n",
      "Epoch 12: Recall@0.8Prec=0.7860, Precision=0.7591\n",
      "  -> Saved best model\n",
      "Epoch 13: Recall@0.8Prec=0.7892, Precision=0.7643\n",
      "  -> Saved best model\n",
      "Epoch 14: Recall@0.8Prec=0.8226, Precision=0.7480\n",
      "  -> Saved best model\n",
      "Epoch 15: Recall@0.8Prec=0.8285, Precision=0.7456\n",
      "  -> Saved best model\n",
      "Best Recall@Precision: 0.8285\n"
     ]
    }
   ],
   "source": [
    "class UNet1D(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "\n",
    "        self.down1 = nn.Sequential(nn.Conv1d(emb_dim, 64, 3, padding=1), nn.ReLU())\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.down2 = nn.Sequential(nn.Conv1d(64, 128, 3, padding=1), nn.ReLU())\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.down3 = nn.Sequential(nn.Conv1d(128, 256, 3, padding=1), nn.ReLU())\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.bottleneck = nn.Sequential(nn.Conv1d(256, 512, 3, padding=1), nn.ReLU())\n",
    "\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv_up3 = nn.Sequential(nn.Conv1d(512+256, 256, 3, padding=1), nn.ReLU())\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv_up2 = nn.Sequential(nn.Conv1d(256+128, 128, 3, padding=1), nn.ReLU())\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv_up1 = nn.Sequential(nn.Conv1d(128+64, 64, 3, padding=1), nn.ReLU())\n",
    "\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x).permute(0,2,1)\n",
    "        d1 = self.down1(x); p1 = self.pool1(d1)\n",
    "        d2 = self.down2(p1); p2 = self.pool2(d2)\n",
    "        d3 = self.down3(p2); p3 = self.pool3(d3)\n",
    "        bn = self.bottleneck(p3)\n",
    "        u3 = self.up3(bn)\n",
    "        c3 = self.conv_up3(torch.cat([u3, d3], dim=1))\n",
    "        u2 = self.up2(c3)\n",
    "        c2 = self.conv_up2(torch.cat([u2, d2], dim=1))\n",
    "        u1 = self.up1(c2)\n",
    "        c1 = self.conv_up1(torch.cat([u1, d1], dim=1))\n",
    "        out = self.pool(c1).squeeze(-1)\n",
    "        return self.fc(out)\n",
    "\n",
    "model2 = UNet1D(len(word2id), emb_dim=100, num_classes=num_classes)\n",
    "train_model(model2, train_dl, val_dl, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa341d21-b521-43b8-b09f-44cfe1efb7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
