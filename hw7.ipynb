{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf6f873",
   "metadata": {},
   "source": [
    "# Домашнее задание № 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4bd487",
   "metadata": {},
   "source": [
    "## Задание 1 (4 балла) \n",
    "\n",
    "Обучите 2 модели похожую по архитектуре на модель из ULMFit для задачи классификации текста (датасет - lenta_40k )\n",
    "В моделях должно быть как минимум два рекуррентных слоя, а финальный вектор для классификации составляться из последнего состояния RNN (так делалось в семинаре), а также AveragePooling и MaxPooling из всех векторов последовательности (конкатенируйте последнее состояния и результаты пулинга). В первой модели используйте обычные слои, а во второй Bidirectional. Рассчитайте по классовую точность/полноту/f-меру для каждой из модели (результаты не должны быть совсем близкие к нулю после обучения на хотя бы нескольких эпохах). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaae3e69-0ce4-45cf-a753-3d66f2be6e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1fc587-cc13-4423-92a5-c50c52e7f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str):\n",
    "    return [t.strip(\".,!?;:'\\\"()[]{}\").lower() for t in text.split()]\n",
    "\n",
    "DATA_PATH = \"lenta_40k.csv.zip\"\n",
    "assert os.path.exists(DATA_PATH), \"Файл lenta_40k.csv.zip не найден\"\n",
    "\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "vocab = Counter()\n",
    "for t in data.text:  # build vocabulary\n",
    "    vocab.update(preprocess(t))\n",
    "\n",
    "word2id = {\"PAD\": 0, \"UNK\": 1}\n",
    "word2id.update({w: i + len(word2id) for i, (w, c) in enumerate(sorted(vocab.items())) if c > 30})\n",
    "\n",
    "id2word = {i: w for w, i in word2id.items()}\n",
    "MAX_LEN = int(np.median([len(preprocess(t)) for t in data.text]) + 30)\n",
    "\n",
    "\n",
    "def encode_texts(texts):\n",
    "    X = np.zeros((len(texts), MAX_LEN), dtype=np.int64)\n",
    "    for i, t in enumerate(texts):\n",
    "        ids = [word2id.get(tok, 1) for tok in preprocess(t)][:MAX_LEN]\n",
    "        X[i, : len(ids)] = ids\n",
    "    return X\n",
    "\n",
    "\n",
    "X = encode_texts(data.text)\n",
    "label2id = {l: i for i, l in enumerate(sorted(data.topic.unique()))}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "y = data.topic.map(label2id).to_numpy(dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7223cc-2942-46b8-bdec-e7a19c810c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.05, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "class TextDS(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].long(), self.y[idx].long()\n",
    "\n",
    "\n",
    "def make_loader(X, y, batch_size=256, shuffle=False):\n",
    "    return DataLoader(TextDS(X, y), batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "train_dl = make_loader(X_train, y_train, shuffle=True)\n",
    "val_dl = make_loader(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3464f80b-177f-405e-96b6-e29ca171b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ULMFit(nn.Module):\n",
    "    \"\"\"2×LSTM (+BiLSTM option) → concat(last, avg‑pool, max‑pool)\"\"\"\n",
    "\n",
    "    def __init__(self, vocab, emb_dim, hid, n_cls, bidir=False):\n",
    "        super().__init__()\n",
    "        self.bidir = bidir\n",
    "        self.embed = nn.Embedding(vocab, emb_dim, padding_idx=0)\n",
    "        self.rnn1 = nn.LSTM(emb_dim, hid, batch_first=True, bidirectional=bidir)\n",
    "        self.rnn2 = nn.LSTM(hid * (2 if bidir else 1), hid, batch_first=True, bidirectional=bidir)\n",
    "        out_dim = hid * (2 if bidir else 1)\n",
    "        self.fc = nn.Linear(out_dim * 3, n_cls)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.embed(x)\n",
    "        o1, _ = self.rnn1(e)\n",
    "        o2, (h2, _) = self.rnn2(o1)\n",
    "\n",
    "        if self.bidir:\n",
    "            last = torch.cat([h2[-2], h2[-1]], dim=1)  # (B, 2H)\n",
    "        else:\n",
    "            last = h2[-1]  # (B, H)\n",
    "\n",
    "        avg_pool = o2.mean(1)\n",
    "        max_pool, _ = o2.max(1)\n",
    "        return self.fc(torch.cat([last, avg_pool, max_pool], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23343d30-53ff-4e9d-9eee-a1f3519e521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cls_report(y_true, y_pred, label_map):\n",
    "    labels = list(range(len(label_map)))    \n",
    "    target_names = [label_map[i] for i in labels] \n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "        target_names=target_names,\n",
    "        digits=3,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    \n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9075995-538c-4c19-96ca-6242f085d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model: nn.Module, name: str, epochs: int = 5):\n",
    "    model.to(device)\n",
    "    opt = Adam(model.parameters(), lr=1e-3)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            loss = crit(model(xb), yb)\n",
    "            opt.zero_grad(); loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        ys, ps = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_dl:\n",
    "                ys.extend(yb.tolist())\n",
    "                ps.extend(model(xb.to(device)).argmax(1).cpu().tolist())\n",
    "        if ep%2==0:\n",
    "            print(f\"\\n[{name}] Epoch {ep} – per‑class metrics:\")\n",
    "            print_cls_report(ys, ps, id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf13537-1466-4a10-b8c1-5d81dc8587cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ULMFit‑Vanilla] Epoch 2 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.000     0.000     0.000        22\n",
      "      Бывший СССР      0.176     0.019     0.034       159\n",
      "              Дом      0.000     0.000     0.000        66\n",
      "         Из жизни      0.000     0.000     0.000        84\n",
      "   Интернет и СМИ      0.000     0.000     0.000       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.284     0.195     0.231       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.226     0.295     0.256       410\n",
      "  Наука и техника      0.229     0.237     0.233       160\n",
      "      Путешествия      0.000     0.000     0.000        21\n",
      "           Россия      0.262     0.711     0.383       481\n",
      "Силовые структуры      0.000     0.000     0.000        60\n",
      "            Спорт      0.143     0.026     0.043       195\n",
      "         Ценности      0.000     0.000     0.000        23\n",
      "        Экономика      0.312     0.063     0.105       239\n",
      "\n",
      "         accuracy                          0.250      2218\n",
      "        macro avg      0.086     0.081     0.068      2218\n",
      "     weighted avg      0.194     0.250     0.181      2218\n",
      "\n",
      "\n",
      "[ULMFit‑Vanilla] Epoch 4 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.000     0.000     0.000        22\n",
      "      Бывший СССР      0.000     0.000     0.000       159\n",
      "              Дом      0.000     0.000     0.000        66\n",
      "         Из жизни      0.083     0.012     0.021        84\n",
      "   Интернет и СМИ      0.000     0.000     0.000       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.274     0.434     0.336       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.565     0.351     0.433       410\n",
      "  Наука и техника      0.279     0.244     0.260       160\n",
      "      Путешествия      0.000     0.000     0.000        21\n",
      "           Россия      0.344     0.771     0.476       481\n",
      "Силовые структуры      0.000     0.000     0.000        60\n",
      "            Спорт      0.329     0.277     0.301       195\n",
      "         Ценности      0.000     0.000     0.000        23\n",
      "        Экономика      0.320     0.423     0.364       239\n",
      "\n",
      "         accuracy                          0.351      2218\n",
      "        macro avg      0.115     0.132     0.115      2218\n",
      "     weighted avg      0.285     0.351     0.293      2218\n",
      "\n",
      "\n",
      "[ULMFit‑Vanilla] Epoch 6 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.000     0.000     0.000        22\n",
      "      Бывший СССР      0.000     0.000     0.000       159\n",
      "              Дом      0.000     0.000     0.000        66\n",
      "         Из жизни      0.100     0.024     0.038        84\n",
      "   Интернет и СМИ      0.000     0.000     0.000       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.329     0.440     0.376       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.448     0.471     0.459       410\n",
      "  Наука и техника      0.475     0.294     0.363       160\n",
      "      Путешествия      0.000     0.000     0.000        21\n",
      "           Россия      0.349     0.740     0.475       481\n",
      "Силовые структуры      0.000     0.000     0.000        60\n",
      "            Спорт      0.812     0.354     0.493       195\n",
      "         Ценности      0.333     0.043     0.077        23\n",
      "        Экономика      0.324     0.460     0.381       239\n",
      "\n",
      "         accuracy                          0.382      2218\n",
      "        macro avg      0.167     0.149     0.140      2218\n",
      "     weighted avg      0.330     0.382     0.328      2218\n",
      "\n",
      "\n",
      "[ULMFit‑Vanilla] Epoch 8 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.000     0.000     0.000        22\n",
      "      Бывший СССР      0.000     0.000     0.000       159\n",
      "              Дом      0.200     0.015     0.028        66\n",
      "         Из жизни      0.160     0.048     0.073        84\n",
      "   Интернет и СМИ      0.000     0.000     0.000       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.364     0.472     0.411       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.389     0.563     0.460       410\n",
      "  Наука и техника      0.496     0.394     0.439       160\n",
      "      Путешествия      0.000     0.000     0.000        21\n",
      "           Россия      0.366     0.636     0.465       481\n",
      "Силовые структуры      0.333     0.017     0.032        60\n",
      "            Спорт      0.796     0.379     0.514       195\n",
      "         Ценности      0.500     0.087     0.148        23\n",
      "        Экономика      0.344     0.469     0.396       239\n",
      "\n",
      "         accuracy                          0.392      2218\n",
      "        macro avg      0.208     0.162     0.156      2218\n",
      "     weighted avg      0.346     0.392     0.341      2218\n",
      "\n",
      "\n",
      "[ULMFit‑Vanilla] Epoch 10 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      1.000     0.091     0.167        22\n",
      "      Бывший СССР      0.333     0.006     0.012       159\n",
      "              Дом      0.000     0.000     0.000        66\n",
      "         Из жизни      0.194     0.083     0.117        84\n",
      "   Интернет и СМИ      0.000     0.000     0.000       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.372     0.447     0.406       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.547     0.444     0.490       410\n",
      "  Наука и техника      0.600     0.338     0.432       160\n",
      "      Путешествия      0.000     0.000     0.000        21\n",
      "           Россия      0.340     0.807     0.478       481\n",
      "Силовые структуры      0.000     0.000     0.000        60\n",
      "            Спорт      0.731     0.390     0.508       195\n",
      "         Ценности      0.500     0.130     0.207        23\n",
      "        Экономика      0.367     0.473     0.413       239\n",
      "\n",
      "         accuracy                          0.404      2218\n",
      "        macro avg      0.262     0.169     0.170      2218\n",
      "     weighted avg      0.395     0.404     0.353      2218\n",
      "\n",
      "\n",
      "[ULMFit‑BiDir] Epoch 2 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.333     0.045     0.080        22\n",
      "      Бывший СССР      0.333     0.006     0.012       159\n",
      "              Дом      0.000     0.000     0.000        66\n",
      "         Из жизни      0.000     0.000     0.000        84\n",
      "   Интернет и СМИ      0.000     0.000     0.000       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.263     0.340     0.297       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.539     0.390     0.453       410\n",
      "  Наука и техника      0.472     0.106     0.173       160\n",
      "      Путешествия      0.000     0.000     0.000        21\n",
      "           Россия      0.340     0.761     0.470       481\n",
      "Силовые структуры      0.429     0.050     0.090        60\n",
      "            Спорт      0.650     0.333     0.441       195\n",
      "         Ценности      0.000     0.000     0.000        23\n",
      "        Экономика      0.271     0.556     0.365       239\n",
      "\n",
      "         accuracy                          0.361      2218\n",
      "        macro avg      0.191     0.136     0.125      2218\n",
      "     weighted avg      0.352     0.361     0.302      2218\n",
      "\n",
      "\n",
      "[ULMFit‑BiDir] Epoch 4 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.333     0.136     0.194        22\n",
      "      Бывший СССР      0.250     0.019     0.035       159\n",
      "              Дом      0.083     0.015     0.026        66\n",
      "         Из жизни      0.115     0.036     0.055        84\n",
      "   Интернет и СМИ      0.429     0.023     0.043       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.315     0.352     0.332       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.501     0.476     0.488       410\n",
      "  Наука и техника      0.433     0.406     0.419       160\n",
      "      Путешествия      0.000     0.000     0.000        21\n",
      "           Россия      0.356     0.780     0.489       481\n",
      "Силовые структуры      0.000     0.000     0.000        60\n",
      "            Спорт      0.753     0.374     0.500       195\n",
      "         Ценности      0.667     0.348     0.457        23\n",
      "        Экономика      0.399     0.452     0.424       239\n",
      "\n",
      "         accuracy                          0.403      2218\n",
      "        macro avg      0.244     0.180     0.182      2218\n",
      "     weighted avg      0.393     0.403     0.355      2218\n",
      "\n",
      "\n",
      "[ULMFit‑BiDir] Epoch 6 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.500     0.091     0.154        22\n",
      "      Бывший СССР      0.222     0.013     0.024       159\n",
      "              Дом      0.125     0.030     0.049        66\n",
      "         Из жизни      0.375     0.071     0.120        84\n",
      "   Интернет и СМИ      1.000     0.023     0.044       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.438     0.358     0.394       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.468     0.495     0.481       410\n",
      "  Наука и техника      0.452     0.444     0.448       160\n",
      "      Путешествия      1.000     0.095     0.174        21\n",
      "           Россия      0.358     0.798     0.494       481\n",
      "Силовые структуры      0.105     0.033     0.051        60\n",
      "            Спорт      0.854     0.421     0.564       195\n",
      "         Ценности      0.667     0.261     0.375        23\n",
      "        Экономика      0.444     0.464     0.454       239\n",
      "\n",
      "         accuracy                          0.421      2218\n",
      "        macro avg      0.369     0.189     0.201      2218\n",
      "     weighted avg      0.469     0.421     0.374      2218\n",
      "\n",
      "\n",
      "[ULMFit‑BiDir] Epoch 8 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.333     0.091     0.143        22\n",
      "      Бывший СССР      0.190     0.025     0.044       159\n",
      "              Дом      0.229     0.167     0.193        66\n",
      "         Из жизни      0.214     0.071     0.107        84\n",
      "   Интернет и СМИ      0.474     0.068     0.119       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.394     0.421     0.407       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.553     0.485     0.517       410\n",
      "  Наука и техника      0.534     0.388     0.449       160\n",
      "      Путешествия      1.000     0.143     0.250        21\n",
      "           Россия      0.371     0.751     0.496       481\n",
      "Силовые структуры      0.188     0.050     0.079        60\n",
      "            Спорт      0.643     0.472     0.544       195\n",
      "         Ценности      0.471     0.348     0.400        23\n",
      "        Экономика      0.402     0.498     0.445       239\n",
      "\n",
      "         accuracy                          0.427      2218\n",
      "        macro avg      0.316     0.209     0.221      2218\n",
      "     weighted avg      0.429     0.427     0.391      2218\n",
      "\n",
      "\n",
      "[ULMFit‑BiDir] Epoch 10 – per‑class metrics:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель      0.000     0.000     0.000         4\n",
      "       Библиотека      0.000     0.000     0.000         0\n",
      "           Бизнес      0.125     0.045     0.067        22\n",
      "      Бывший СССР      0.318     0.044     0.077       159\n",
      "              Дом      0.417     0.152     0.222        66\n",
      "         Из жизни      0.205     0.107     0.141        84\n",
      "   Интернет и СМИ      0.350     0.053     0.092       132\n",
      "             Крым      0.000     0.000     0.000         2\n",
      "    Культпросвет       0.000     0.000     0.000         1\n",
      "         Культура      0.467     0.403     0.432       159\n",
      "          Легпром      0.000     0.000     0.000         0\n",
      "              Мир      0.588     0.463     0.518       410\n",
      "  Наука и техника      0.401     0.456     0.427       160\n",
      "      Путешествия      1.000     0.048     0.091        21\n",
      "           Россия      0.380     0.730     0.500       481\n",
      "Силовые структуры      0.125     0.050     0.071        60\n",
      "            Спорт      0.669     0.497     0.571       195\n",
      "         Ценности      0.562     0.391     0.462        23\n",
      "        Экономика      0.376     0.548     0.446       239\n",
      "\n",
      "         accuracy                          0.430      2218\n",
      "        macro avg      0.315     0.210     0.217      2218\n",
      "     weighted avg      0.437     0.430     0.395      2218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vanilla = ULMFit(len(word2id), 100, 128, len(label2id), bidir=False)\n",
    "bidir   = ULMFit(len(word2id), 100, 128, len(label2id), bidir=True)\n",
    "\n",
    "train_eval(vanilla, \"ULMFit‑Vanilla\", epochs=10)\n",
    "train_eval(bidir,  \"ULMFit‑BiDir\",  epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d6eea",
   "metadata": {},
   "source": [
    "## Задание 2 (6 баллов)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c07cf",
   "metadata": {},
   "source": [
    "На данных википедии (wikiann) обучите и сравните 3 модели:  \n",
    "1) модель в которой как минимум два рекуррентных слоя, причем один из них GRU, а другой LSTM \n",
    "2) модель в которой как минимум 3 рекуррентных слоя идут друг за другом и при этом 2-ой и 3-й слои еще имеют residual connection к изначальным эмбедингам. Для того, чтобы сделать residual connection вам нужно будет использовать одинаковую размерность эмбедингов и количество unit'ов в RNN слоях, чтобы их можно было просуммировать \n",
    "3) модель в которой будут и рекуррентные и сверточные слои (как минимум 2 rnn и как минимум 2 cnn слоя). В cnn слоях будьте аккуратны с укорачиванием последовательности и используйте паддинг\n",
    "\n",
    "\n",
    "\n",
    "Сравните качество по метрикам (точность/полнота/f-мера). Также придумайте несколько сложных примеров и проверьте, какие сущности определяет каждая из моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb704b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiANN split sizes: {'validation': 10000, 'test': 10000, 'train': 20000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c275bce8793742a9bd6e3d961700b3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40afaf3702241f3b54f09c0b7ba7bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0131d3fd22487487eaeced1f4e0a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
    "\n",
    "wiki = load_dataset(\"wikiann\", \"en\")\n",
    "print(\"WikiANN split sizes:\", {k: len(v) for k, v in wiki.items()})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "def tokenize_and_align(batch):\n",
    "    enc = tokenizer(\n",
    "        batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "\n",
    "    aligned_labels = []\n",
    "    for i, encoding in enumerate(enc.encodings):\n",
    "        word_ids = encoding.word_ids\n",
    "        sent_labels = [batch[\"ner_tags\"][i][wid] if wid is not None else -100 for wid in word_ids]\n",
    "        aligned_labels.append(sent_labels)\n",
    "\n",
    "    enc[\"labels\"] = aligned_labels\n",
    "    return {k: enc[k] for k in (\"input_ids\", \"attention_mask\", \"labels\")}\n",
    "\n",
    "encoded = wiki.map(tokenize_and_align, batched=True, remove_columns=wiki[\"train\"].column_names)\n",
    "train_ds, val_ds = encoded[\"train\"], encoded[\"validation\"]\n",
    "\n",
    "def make_loader_ner(ds, bs=32, shuffle=False):\n",
    "    return DataLoader(ds, batch_size=bs, shuffle=shuffle, collate_fn=data_collator)\n",
    "\n",
    "train_ld = make_loader_ner(train_ds, shuffle=True)\n",
    "val_ld   = make_loader_ner(val_ds)\n",
    "\n",
    "tags = wiki[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "class NERModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, rnn_cells, use_residual=False, use_cnn=False):\n",
    "        super().__init__()\n",
    "        self.use_res, self.use_cnn = use_residual, use_cnn\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.rnns = nn.ModuleList()\n",
    "        in_dim = emb_dim\n",
    "        for cell in rnn_cells:\n",
    "            self.rnns.append(cell(in_dim, hidden_dim, batch_first=True))\n",
    "            in_dim = hidden_dim\n",
    "        if use_cnn:\n",
    "            self.conv1 = nn.Conv1d(hidden_dim, hidden_dim, 3, padding=1)\n",
    "            self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, 3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim, len(tags))\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        emb = self.embed(input_ids)\n",
    "        out = emb\n",
    "        for i, rnn in enumerate(self.rnns):\n",
    "            out, _ = rnn(out)\n",
    "            if self.use_res and i > 0:\n",
    "                out = out + emb\n",
    "        if self.use_cnn:\n",
    "            o = F.relu(self.conv1(out.permute(0, 2, 1)))\n",
    "            out = F.relu(self.conv2(o)).permute(0, 2, 1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd5b0ed9-bee5-448a-bb56-9a5fda0ad544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report as ner_classification_report\n",
    "from tqdm import tqdm\n",
    "def build_models():\n",
    "    return [\n",
    "        (\"GRU+LSTM\", NERModel(tokenizer.vocab_size, 64, 64, [nn.GRU, nn.LSTM])),\n",
    "        (\"Res3RNN\", NERModel(tokenizer.vocab_size, 64, 64, [nn.LSTM]*3, use_residual=True)),\n",
    "        (\"RNN+CNN\", NERModel(tokenizer.vocab_size, 64, 64, [nn.LSTM, nn.LSTM], use_cnn=True)),\n",
    "    ]\n",
    "\n",
    "\n",
    "def train_ner(model, name: str, epochs: int = 3):\n",
    "    model.to(device)\n",
    "    opt = Adam(model.parameters(), lr=2e-3)\n",
    "    crit = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_ld):\n",
    "            ids, labels = batch[\"input_ids\"].to(device), batch[\"labels\"].to(device)\n",
    "            logits = model(ids)                          # (B, L, C)\n",
    "            loss = crit(logits.view(-1, len(tags)), labels.view(-1))\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        corr = tot = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_ld:\n",
    "                ids, labels = batch[\"input_ids\"].to(device), batch[\"labels\"].to(device)\n",
    "                preds = model(ids).argmax(-1)\n",
    "                mask = labels != -100\n",
    "                corr += (preds[mask] == labels[mask]).sum().item()\n",
    "                tot += mask.sum().item()\n",
    "        token_acc = corr / tot\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_ld):\n",
    "                ids, labels = batch[\"input_ids\"].to(device), batch[\"labels\"].to(device)\n",
    "                preds = model(ids).argmax(-1).cpu().tolist()\n",
    "                true  = labels.cpu().tolist()\n",
    "                for pred_seq, true_seq in zip(preds, true):\n",
    "                    seq_preds = []\n",
    "                    seq_trues = []\n",
    "                    for p, t in zip(pred_seq, true_seq):\n",
    "                        if t == -100:\n",
    "                            continue\n",
    "                        seq_preds.append(tags[p])\n",
    "                        seq_trues.append(tags[t])\n",
    "                    all_preds.append(seq_preds)\n",
    "                    all_labels.append(seq_trues)\n",
    "\n",
    "        print(f\"\\n[{name}] Epoch {ep}\")\n",
    "        print(f\"Token-accuracy = {token_acc:.3f}\")\n",
    "        print(\"Entity-level precision/recall/F1:\")\n",
    "        print(ner_classification_report(all_labels, all_preds, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af3d34d-f1e0-4481-ae80-c7fb7c22ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:09<00:00,  9.04it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [00:10<00:00, 29.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[GRU+LSTM] Epoch 1\n",
      "Token-accuracy = 0.452\n",
      "Entity-level precision/recall/F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.00      0.00      0.00      9726\n",
      "         ORG       0.00      0.00      0.00      7703\n",
      "         PER       0.00      0.00      0.00      6919\n",
      "\n",
      "   micro avg       0.00      0.00      0.00     24348\n",
      "   macro avg       0.00      0.00      0.00     24348\n",
      "weighted avg       0.00      0.00      0.00     24348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [01:10<00:00,  8.91it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [00:10<00:00, 29.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[GRU+LSTM] Epoch 2\n",
      "Token-accuracy = 0.452\n",
      "Entity-level precision/recall/F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.00      0.00      0.00      9726\n",
      "         ORG       0.00      0.00      0.00      7703\n",
      "         PER       0.00      0.00      0.00      6919\n",
      "\n",
      "   micro avg       0.00      0.00      0.00     24348\n",
      "   macro avg       0.00      0.00      0.00     24348\n",
      "weighted avg       0.00      0.00      0.00     24348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [00:10<00:00, 60.57it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [00:03<00:00, 83.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Res3RNN] Epoch 1\n",
      "Token-accuracy = 0.652\n",
      "Entity-level precision/recall/F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.27      0.33      0.30      9726\n",
      "         ORG       0.10      0.09      0.09      7703\n",
      "         PER       0.14      0.27      0.19      6919\n",
      "\n",
      "   micro avg       0.18      0.24      0.21     24348\n",
      "   macro avg       0.17      0.23      0.19     24348\n",
      "weighted avg       0.18      0.24      0.20     24348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [00:09<00:00, 63.09it/s]\n",
      "100%|█████████████████████████████████████████| 313/313 [00:04<00:00, 74.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Res3RNN] Epoch 2\n",
      "Token-accuracy = 0.713\n",
      "Entity-level precision/recall/F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.36      0.40      0.38      9726\n",
      "         ORG       0.14      0.20      0.17      7703\n",
      "         PER       0.26      0.32      0.29      6919\n",
      "\n",
      "   micro avg       0.25      0.31      0.28     24348\n",
      "   macro avg       0.25      0.31      0.28     24348\n",
      "weighted avg       0.26      0.31      0.28     24348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [00:08<00:00, 77.58it/s]\n",
      "100%|████████████████████████████████████████| 313/313 [00:02<00:00, 154.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RNN+CNN] Epoch 1\n",
      "Token-accuracy = 0.681\n",
      "Entity-level precision/recall/F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.32      0.40      0.36      9726\n",
      "         ORG       0.19      0.16      0.17      7703\n",
      "         PER       0.21      0.27      0.24      6919\n",
      "\n",
      "   micro avg       0.26      0.29      0.27     24348\n",
      "   macro avg       0.24      0.28      0.26     24348\n",
      "weighted avg       0.25      0.29      0.27     24348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 625/625 [00:07<00:00, 79.06it/s]\n",
      "100%|████████████████████████████████████████| 313/313 [00:02<00:00, 153.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RNN+CNN] Epoch 2\n",
      "Token-accuracy = 0.753\n",
      "Entity-level precision/recall/F1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.52      0.45      0.48      9726\n",
      "         ORG       0.28      0.29      0.29      7703\n",
      "         PER       0.37      0.50      0.43      6919\n",
      "\n",
      "   micro avg       0.39      0.41      0.40     24348\n",
      "   macro avg       0.39      0.41      0.40     24348\n",
      "weighted avg       0.40      0.41      0.40     24348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = build_models()\n",
    "for n, net in models:\n",
    "        train_ner(net, n, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28dc791d-5412-4601-8478-2ac0109946ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU+LSTM [('apple', 'O'), ('рассматривает', 'O'), ('покупку', 'O'), ('стартапа', 'O'), ('в', 'O'), ('области', 'O'), ('искусственного', 'O'), ('интеллекта', 'O')]\n",
      "Res3RNN [('apple', 'O'), ('рассматривает', 'O'), ('покупку', 'I-PER'), ('стартапа', 'O'), ('в', 'O'), ('области', 'I-ORG'), ('искусственного', 'I-ORG'), ('интеллекта', 'O')]\n",
      "RNN+CNN [('apple', 'I-ORG'), ('рассматривает', 'I-ORG'), ('покупку', 'I-ORG'), ('стартапа', 'I-ORG'), ('в', 'I-ORG'), ('области', 'I-ORG'), ('искусственного', 'I-ORG'), ('интеллекта', 'I-ORG')]\n",
      "GRU+LSTM [('в', 'O'), ('понедельник', 'O'), ('москва', 'O'), ('и', 'O'), ('питер', 'O'), ('встретились', 'O'), ('на', 'O'), ('стадионе', 'O')]\n",
      "Res3RNN [('в', 'I-ORG'), ('понедельник', 'I-ORG'), ('москва', 'I-ORG'), ('и', 'I-ORG'), ('питер', 'I-ORG'), ('встретились', 'I-ORG'), ('на', 'I-ORG'), ('стадионе', 'I-ORG')]\n",
      "RNN+CNN [('в', 'I-ORG'), ('понедельник', 'I-ORG'), ('москва', 'I-ORG'), ('и', 'I-ORG'), ('питер', 'I-ORG'), ('встретились', 'I-ORG'), ('на', 'I-ORG'), ('стадионе', 'I-ORG')]\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"Apple рассматривает покупку стартапа в области искусственного интеллекта\",\n",
    "    \"В понедельник Москва и Питер встретились на стадионе\",\n",
    "]\n",
    "for text in samples:\n",
    "    tokens = preprocess(text)\n",
    "    ids = torch.tensor(encode_texts([text])).to(device)\n",
    "    for name, model in models:\n",
    "        pred = model(ids).argmax(-1)[0].tolist()\n",
    "        print(name, list(zip(tokens, [tags[p] for p in pred[:len(tokens)]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0f2c0-899c-4309-9e27-80053a266169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
