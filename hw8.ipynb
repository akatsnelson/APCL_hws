{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dba7c0d",
   "metadata": {},
   "source": [
    "# Домашнее задание № 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb51a4",
   "metadata": {},
   "source": [
    "### Задание 1 (10 баллов).\n",
    "Это задание основано на этой тетрадке - https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/transfer_learning_hg/Fine_tunining_pretrained_LMs_torch.ipynb\n",
    "\n",
    "На датасете lenta_sample.ru  дообучите две модели - modernbert-base (из семинара) и rumodernbert-base (https://huggingface.co/deepvk/RuModernBERT-base). Оцените разницу в качестве сравнив поклассовые метрики (classification_report)\n",
    "\n",
    "Для обоих моделей качество должно быть >0.10 по f-мере (прогоните несколько экспериментов если у вас получаются нули, изменяя параметры).\n",
    "Также для обоих моделей попробуйте дообучать модель и целиком и дообучать только последний слой. \n",
    "Для RuModernBERT дополнительно сравните модель, которая использует первый вектор (cls токен, как в семинаре), так и усредненный вектор по всем hidden_state, который выдает bert. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb83385-2a98-4422-a549-1fafc1aafea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_env/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/ml_env/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <EA7F9DF5-8854-31D8-89D4-BD566CAF4DEA> /opt/anaconda3/envs/ml_env/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <E3D17B4A-4867-3D49-BC92-E04C28EE0F45> /opt/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f397e87f-f5a9-4f04-a749-577cfa2d449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_label_maps(dataset: Dataset):\n",
    "    labels: List[str] = sorted(set(dataset[\"topic\"]))\n",
    "    label2id = {l: i for i, l in enumerate(labels)}\n",
    "    id2label = {i: l for l, i in label2id.items()}\n",
    "    return label2id, id2label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7360604d-a17e-41dd-8c5a-6503b5db0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example: dict, label2id: Dict[str, int]):\n",
    "    return {\"text\": example[\"text\"], \"label\": label2id[example[\"topic\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588be544-1b41-4317-8ea1-16c32c1fd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(examples: dict, tokenizer: AutoTokenizer):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc671aa-b44b-4e97-8558-815e5e8ab586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolingBERT(nn.Module):\n",
    "    def __init__(self, model_name: str, num_labels: int):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden = outputs.last_hidden_state \n",
    "        mask = attention_mask.unsqueeze(-1).float()\n",
    "        pooled = (hidden * mask).sum(1) / mask.sum(1)\n",
    "        logits = self.classifier(pooled)\n",
    "        loss = self.loss_fn(logits, labels) if labels is not None else None\n",
    "        return {\"loss\": loss, \"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2fb4953-bd17-4d2e-a212-a766b96b667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, id2label):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, 1)\n",
    "    report_str = classification_report(\n",
    "        labels,\n",
    "        preds,\n",
    "        target_names=[id2label[i] for i in range(len(id2label))],\n",
    "        zero_division=0,\n",
    "    )\n",
    "    print(\"\\n\" + report_str)\n",
    "    report = classification_report(\n",
    "        labels,\n",
    "        preds,\n",
    "        target_names=[id2label[i] for i in range(len(id2label))],\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return {\"macro_f1\": report[\"macro avg\"][\"f1-score\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1077fd4e-89cc-4e51-94d1-a023568657c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"modern_full\": {\n",
    "        \"name\": \"answerdotai/ModernBERT-base\",\n",
    "        \"freeze\": False,\n",
    "        \"custom_head\": None,\n",
    "    },\n",
    "    \"modern_cls_only\": {\n",
    "        \"name\": \"answerdotai/ModernBERT-base\",\n",
    "        \"freeze\": True,\n",
    "        \"custom_head\": None,\n",
    "    },\n",
    "    \"rumodern_cls_full\": {\n",
    "        \"name\": \"deepvk/RuModernBERT-base\",\n",
    "        \"freeze\": False,\n",
    "        \"custom_head\": None,\n",
    "    },\n",
    "    \"rumodern_mean_full\": {\n",
    "        \"name\": \"deepvk/RuModernBERT-base\",\n",
    "        \"freeze\": False,\n",
    "        \"custom_head\": MeanPoolingBERT,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6450413-2d5a-43cc-9147-54e0529b723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(cfg: dict, dsets: dict, id2label: dict):\n",
    "    model_name = cfg[\"name\"]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "    tokenized_train = dsets[\"train\"].map(\n",
    "        lambda x: tokenize_fn(x, tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\", \"topic\"],\n",
    "    )\n",
    "    tokenized_val = dsets[\"validation\"].map(\n",
    "        lambda x: tokenize_fn(x, tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\", \"topic\"],\n",
    "    )\n",
    "\n",
    "    if cfg[\"custom_head\"]:\n",
    "        model = cfg[\"custom_head\"](model_name, num_labels=len(id2label))\n",
    "    else:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=len(id2label),\n",
    "            trust_remote_code=True,\n",
    "            id2label=id2label,\n",
    "            label2id={v: k for k, v in id2label.items()},\n",
    "        )\n",
    "\n",
    "    if cfg[\"freeze\"] and not cfg[\"custom_head\"]:\n",
    "        for p in model.base_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/{model_name.replace('/', '_')}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"no\",\n",
    "        bf16=torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        compute_metrics=lambda p: compute_metrics(p, id2label),\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(f\"Final macro-F1: {metrics['eval_macro_f1']:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0578c42-5fe0-456d-a289-b46b8a8f6f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba747df76914bf0b0b15b437a93cc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "-> modern_full\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d05a634e80d40c5be1712f2f09ecdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26919fe03505490ab2c1bc1fbe5cd92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/ml_env/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/pm/xshykg4d7wvgy969hfm8hgp40000gn/T/ipykernel_58439/1525860524.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='5545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  11/5545 00:09 < 1:33:52, 0.98 it/s, Epoch 0.01/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('lenta_40k.csv.zip', compression=\"zip\")\n",
    "raw = Dataset.from_pandas(df)\n",
    "\n",
    "label2id, id2label = build_label_maps(raw)\n",
    "ds = raw.map(lambda ex: preprocess(ex, label2id))\n",
    "\n",
    "dsets = ds.train_test_split(test_size=0.2)\n",
    "dsets[\"validation\"] = dsets.pop(\"test\")\n",
    "\n",
    "for tag, cfg in MODELS.items():\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"-> {tag}\")\n",
    "    train_one(cfg, dsets, id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd7afe-7fc5-4186-8ea2-a38b5d4bbfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844faa99-955f-4024-80aa-854c68820e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
