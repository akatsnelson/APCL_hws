{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ce6aa68",
      "metadata": {
        "id": "9ce6aa68"
      },
      "source": [
        "# Задание 1.\n",
        "\n",
        "Проанализируйте текст ниже с помощью майстема. Уберите из получившегося списка элементы, у которых нет грамматического разбора.\n",
        "Далее создайте отдельный список только с частями речи для каждого слова.\n",
        "Превратите этот список отдельных частеречных тэгов в список частеречных триграммов (с пересечением).\n",
        "`['N', \"ADJ\", \"V\", \"J\"] -> [(\"N\", \"ADJ\", \"V\"), (\"ADJ\", \"V\", \"\"J\")]` (тэги не настоящие для примера)\n",
        "\n",
        "Найдите самый частотный частеречный триграмм. Вставьте триграмм и количество вхождений в форму в таком формате:\n",
        "\n",
        "`N ADJ V;3` (три тэга через пробел и количество вхождение через точку с запятой)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "54488642",
      "metadata": {
        "id": "54488642"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Античит-движки для игр — это ещё одна крупная область Windows, которая использует драйверы на уровне ядра. Microsoft ведёт переговоры с разработчиками игр о том, как сократить объём использования ядра. Riot Games сообщила Microsoft о готовности следовать потенциальным изменениям безопасности Windows и сократить влияние на ядро ОС.\n",
        "\n",
        "Летом этого года Microsoft готовится к выпуску обновления Windows, которое будет включать новую функцию Quick Machine Recovery. Функция предназначена для быстрого восстановления системы после сбоя. Ранее Microsoft сообщила о планах сменить синий экран смерти на чёрный.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5d0ff2b7",
      "metadata": {
        "id": "5d0ff2b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2832ba77-1ad9-4dff-f847-8ceb4b9c4151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S PR S;5\n"
          ]
        }
      ],
      "source": [
        "from pymystem3 import Mystem\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "m = Mystem()\n",
        "parsed = m.analyze(text)\n",
        "\n",
        "tags = [item['analysis'][0]['gr'] for item in parsed if 'analysis' in item and item['analysis']]\n",
        "pos_tags = [re.split('[,=]', tag)[0] for tag in tags]\n",
        "trigrams = [(pos_tags[i], pos_tags[i+1], pos_tags[i+2]) for i in range(len(pos_tags)-2)]\n",
        "trigram_counts = Counter(trigrams)\n",
        "most_common_trigram, freq = trigram_counts.most_common(1)[0]\n",
        "\n",
        "\n",
        "print(f\"{most_common_trigram[0]} {most_common_trigram[1]} {most_common_trigram[2]};{freq}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede26498",
      "metadata": {
        "id": "ede26498"
      },
      "source": [
        "## Задание 2.\n",
        "\n",
        "Вам дана последовательность с правильными ответами для задачи многоклассовой классификации. А также массив с предсказаниями такой же длины, но в виде вероятностей для каждого класса. Для каждой строчки выберете самый вероятный класс.\n",
        "\n",
        "Рассчитайте TP,FP,TN,FN для каждого класса. Рассчитайте точность для каждого класса по отдельности. Найдите класс с самой высокой точностью и вставьте значение точности для этого класса в форму как ответ. Округлите ответ до 2 знака после запятой (например, `0.12`)\n",
        "\n",
        "*Для этого задания не используйте готовые решения (можно использовать только numpy для работы с массивом вероятностей и встроенные библиотеки вроде collections.Counter для удобства)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "fbaeb58a",
      "metadata": {
        "id": "fbaeb58a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ef070800",
      "metadata": {
        "id": "ef070800"
      },
      "outputs": [],
      "source": [
        "multiclass_true = [0,3,0,0,3,0,0,1,2,4,1,2,4,0,2,0,4,1,2,4,1,1,4,1,2,0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9237b3dc",
      "metadata": {
        "id": "9237b3dc"
      },
      "outputs": [],
      "source": [
        "probas = np.array([[0.14283307, 0.69125398, 0.08801677, 0.05890497, 0.01899121],\n",
        "       [0.05017326, 0.16837714, 0.09787715, 0.37586925, 0.3077032 ],\n",
        "       [0.07349622, 0.20737874, 0.06666821, 0.0582571 , 0.59419973],\n",
        "       [0.08704361, 0.18970222, 0.16262277, 0.08630088, 0.47433053],\n",
        "       [0.16137361, 0.21450292, 0.22870402, 0.24422044, 0.151199  ],\n",
        "       [0.268094  , 0.43761478, 0.12385365, 0.04917541, 0.12126215],\n",
        "       [0.27161954, 0.01412896, 0.11056462, 0.09468905, 0.50899783],\n",
        "       [0.09363269, 0.02693918, 0.33977914, 0.39909705, 0.14055195],\n",
        "       [0.29520778, 0.05132426, 0.06673668, 0.45254433, 0.13418695],\n",
        "       [0.15421375, 0.22964685, 0.16662999, 0.21004033, 0.23946907],\n",
        "       [0.24755032, 0.24628846, 0.12956078, 0.24832473, 0.12827571],\n",
        "       [0.11797719, 0.03232272, 0.07293219, 0.52455883, 0.25220907],\n",
        "       [0.75835945, 0.07189134, 0.06032446, 0.04986686, 0.05955789],\n",
        "       [0.02601848, 0.26673495, 0.03124844, 0.21992134, 0.4560768 ],\n",
        "       [0.58059452, 0.03148405, 0.11400383, 0.14452069, 0.12939691],\n",
        "       [0.08215579, 0.32887402, 0.10776154, 0.30880314, 0.17240552],\n",
        "       [0.11467395, 0.07250172, 0.03868279, 0.04358503, 0.73055651],\n",
        "       [0.09546111, 0.22318028, 0.04797582, 0.42230537, 0.21107742],\n",
        "       [0.17088269, 0.31617363, 0.02329777, 0.26480448, 0.22484143],\n",
        "       [0.1573525 , 0.04416687, 0.59056588, 0.0854817 , 0.12243306],\n",
        "       [0.16300152, 0.224168  , 0.11143585, 0.09995103, 0.4014436 ],\n",
        "       [0.17649215, 0.32146966, 0.21575183, 0.0238604 , 0.26242596],\n",
        "       [0.00860468, 0.01201256, 0.96059244, 0.00327634, 0.01551398],\n",
        "       [0.06455855, 0.11772163, 0.25971348, 0.32510222, 0.23290411],\n",
        "       [0.04150647, 0.1329052 , 0.22146507, 0.03930956, 0.5648137 ],\n",
        "       [0.12671909, 0.01486602, 0.77637796, 0.06239952, 0.01963741]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "6666e076",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6666e076",
        "outputId": "e93bdc48-bf31-44c5-d274-c45984a64478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "predicted = np.argmax(probas, axis=1)\n",
        "num_classes = probas.shape[1]\n",
        "\n",
        "TP = np.zeros(num_classes, dtype=int)\n",
        "FP = np.zeros(num_classes, dtype=int)\n",
        "FN = np.zeros(num_classes, dtype=int)\n",
        "TN = np.zeros(num_classes, dtype=int)\n",
        "\n",
        "for true, pred in zip(multiclass_true, predicted):\n",
        "    for cls in range(num_classes):\n",
        "        if true == cls and pred == cls:\n",
        "            TP[cls] += 1\n",
        "        elif pred == cls and true != cls:\n",
        "            FP[cls] += 1\n",
        "        elif true == cls and pred != cls:\n",
        "            FN[cls] += 1\n",
        "        else:\n",
        "            TN[cls] += 1\n",
        "\n",
        "precisions = np.divide(TP, TP + FP, out=np.zeros_like(TP, dtype=float), where=(TP + FP) != 0)\n",
        "max_precision = round(np.max(precisions), 2)\n",
        "print(max_precision)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TP, FP, FN, TN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjqpS3YCMCEq",
        "outputId": "b7828a5b-4cd0-4e46-aab1-0c088d82faaa"
      },
      "id": "TjqpS3YCMCEq",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 0, 2, 2]),\n",
              " array([2, 4, 3, 6, 6]),\n",
              " array([8, 5, 5, 0, 3]),\n",
              " array([16, 16, 18, 18, 15]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dd46798",
      "metadata": {
        "id": "3dd46798"
      },
      "source": [
        "## Задание 3\n",
        "\n",
        "Загрузите токенизатор и модель `sentence-transformers/all-MiniLM-L6-v2`. Токенизируйте и рассчитайте векторные представления для двух приведенных ниже текстов. Усредните векторные представления токенов каждого из текстов так, чтобы для каждого из текстов получился вектор размером 384.\n",
        "Рассчитайте косинусную близость между двумя этим векторами, округлите его до 2 знака после запятой и вставьте число в форму.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "1b8396f6",
      "metadata": {
        "id": "1b8396f6"
      },
      "outputs": [],
      "source": [
        "text1 = \"Hounds display remarkable fidelity towards their owners, often brightening days through affectionate gestures.\"\n",
        "text2 = \"Domestic pups exhibit steadfast allegiance to caregivers, frequently lifting spirits via tender behaviors.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "def mean_token_embedding(text: str) -> torch.Tensor:\n",
        "    encoded = tokenizer(text, return_tensors=\"pt\")\n",
        "    attention_mask = encoded[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded)\n",
        "\n",
        "    last_hidden = outputs.last_hidden_state.squeeze(0)\n",
        "    mask = attention_mask.squeeze(0).bool()\n",
        "    token_vecs = last_hidden[mask]\n",
        "    return token_vecs.mean(dim=0)\n",
        "\n",
        "vec1 = mean_token_embedding(text1)\n",
        "vec2 = mean_token_embedding(text2)\n",
        "\n",
        "cos_sim = F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0)).item()\n",
        "\n",
        "print(f\"{cos_sim:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHgVVmSmRjOO",
        "outputId": "b306f4de-5ac9-4d1a-ef45-717564ffb278"
      },
      "id": "rHgVVmSmRjOO",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4fb936",
      "metadata": {
        "id": "4b4fb936"
      },
      "source": [
        "# Задание 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af1adfb",
      "metadata": {
        "id": "5af1adfb"
      },
      "source": [
        "Используя модель \"HuggingFaceTB/SmolLM2-135M\" (huggingface), сгенерируйте продолжение следующего промпта:\n",
        "\"I woke up and saw \".\n",
        "\n",
        "Используйте следующее параметры при генерации: максимальная длина продолжения - 40 токенов, отсутствие повторов длиной 2 токена, отсутствие семплирования (выбирается только самый вероятный токен).\n",
        "\n",
        "Модель должна быть загружена в 4bit формате.\n",
        "\n",
        "Вставьте сгенерированный текст в форму целиком (кавычки лучше не включать, но сработает и с ними)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "aaff9986",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaff9986",
        "outputId": "1487bc57-bda3-4342-9d34-603b8479ea6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "prompt = \"I woke up and saw \"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=40,\n",
        "    no_repeat_ngram_size=2,\n",
        "    do_sample=False,\n",
        "    num_beams=1,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "continuation = tokenizer.decode(\n",
        "    output[0][len(input_ids[0]):],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "print(continuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FCvFyEqQw-h",
        "outputId": "719d9451-46f2-4a97-d556-5a351e3b7bc8"
      },
      "id": "6FCvFyEqQw-h",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12, 23, and 33.  I had to go to the hospital to get the 43 and the other 53 were all in the same hospital.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vM8AuAtBSgFN"
      },
      "id": "vM8AuAtBSgFN",
      "execution_count": 45,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}