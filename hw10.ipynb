{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dba7c0d",
   "metadata": {},
   "source": [
    "# Домашнее задание № 10. Машинный перевод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yj7aripVIsbG",
   "metadata": {
    "id": "Yj7aripVIsbG"
   },
   "source": [
    "## Задание 1 (6 баллов + 2 доп балла).\n",
    "Нужно обучить трансформер на том же корпусе но в другую сторону - с русского на английский.\n",
    "Можно использовать как основу первый или второй способ реализации (с MultiheadAttention или с nn.Transformer). Подберите несколько тестовых примеров для проверки обучения на каждой эпохе. \n",
    "\n",
    "Параметры ниже точно работают в колабе и модель обучается достаточно быстро. Попробуйте их немного увеличить (batch size возможно придется наоборот уменьшить). Обучайте модель хотя бы 5 эпох, а желательно больше, чтобы тестовые примеры начали переводиться более менее адекватно. \n",
    "\n",
    "После обучения возьмите хотя бы 100 примером из тестовой части параллельного корпуса и переведите их. Оцените качество переводов с помощью метрики BLEU (пример использования ниже)\n",
    "Найдите лучшие (как минимум 5) переводы согласно этой метрике и проверьте действительно ли они хорошие. Если все переводы нулевые, то пообучайте модель подольше.\n",
    "\n",
    "Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Сейчас она работает только с одним текстом - это не эффективно. Можно генерировать переводы сразу для нескольких текстов (батча). Главная сложность с таким подходом состоит в том, что генерируемые тексты будут заканчиваться в разное время и нужно сделать столько итераций, сколько нужно для завершения всех текстов (т.е. условие на то, что последний токен не равен [EOS] в текущем коде не сработает). \n",
    "ВАЖНО - недостаточно просто изменить входной аргумент с text на texts и добавить еще один цикл по texts! Сама модель должна вызываться на нескольких текстах! Функция с batch prediction должна работать быстрее, поэтому переведите всю тестовую выборку и оцените качество BLEU на всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d202c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В колабе установите torchtune и torchao, чтобы семинарская тетрадка работала\n",
    "!pip install torchtune torchao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f35e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4548019047027907\n"
     ]
    }
   ],
   "source": [
    "# пример использования BLEU\n",
    "# обратите внимание что текты должны быть токенизированы\n",
    "import nltk\n",
    "\n",
    "hypothesis = ['It', 'is', 'a', 'cat', 'at', 'room'] # замените на перевод вашей модели\n",
    "reference = ['It', 'is', 'a', 'cat', 'inside', 'the', 'room'] # замените на эталонный перевод\n",
    "\n",
    "\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, auto_reweigh=True)\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c84d3a-4986-4b7f-9f7c-c529345e99c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: mps\n"
     ]
    }
   ],
   "source": [
    "import math, time, random, itertools, nltk, sentencepiece as spm, torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5efa8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB   = 32\n",
    "HEADS = 4 \n",
    "FF    = EMB*2\n",
    "LAYERS= 2\n",
    "BATCH = 32\n",
    "EPOCHS= 5\n",
    "VOCAB = 5000\n",
    "\n",
    "BOS, EOS, PAD, UNK = 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9fbd8a0-2da7-4862-a857-2bfb52da3ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-29 23:50:44--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
      "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
      "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 121340806 (116M)\n",
      "Saving to: ‘opus.en-ru-train.ru’\n",
      "\n",
      "opus.en-ru-train.ru 100%[===================>] 115.72M  4.49MB/s    in 30s     \n",
      "\n",
      "2025-06-29 23:51:15 (3.85 MB/s) - ‘opus.en-ru-train.ru’ saved [121340806/121340806]\n",
      "\n",
      "--2025-06-29 23:51:16--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
      "129.215.32.28a.statmt.org (data.statmt.org)... \n",
      "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 67760131 (65M)\n",
      "Saving to: ‘opus.en-ru-train.en’\n",
      "\n",
      "opus.en-ru-train.en 100%[===================>]  64.62M  5.16MB/s    in 15s     \n",
      "\n",
      "2025-06-29 23:51:31 (4.34 MB/s) - ‘opus.en-ru-train.en’ saved [67760131/67760131]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
    "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a474db4-cbce-4402-b58f-310f8149d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-29 23:44:44--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
      "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
      "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 305669 (299K)\n",
      "Saving to: ‘opus.en-ru-test.ru’\n",
      "\n",
      "opus.en-ru-test.ru  100%[===================>] 298.50K   418KB/s    in 0.7s    \n",
      "\n",
      "2025-06-29 23:44:47 (418 KB/s) - ‘opus.en-ru-test.ru’ saved [305669/305669]\n",
      "\n",
      "--2025-06-29 23:44:47--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n",
      "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
      "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 173307 (169K)\n",
      "Saving to: ‘opus.en-ru-test.en’\n",
      "\n",
      "opus.en-ru-test.en  100%[===================>] 169.25K   205KB/s    in 0.8s    \n",
      "\n",
      "2025-06-29 23:44:49 (205 KB/s) - ‘opus.en-ru-test.en’ saved [173307/173307]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
    "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32aa70fc-c933-441d-90be-59dd7647210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spm(prefix, files):\n",
    "    if Path(prefix+\".model\").exists():\n",
    "        return spm.SentencePieceProcessor(model_file=prefix+\".model\")\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        input=\",\".join(files), model_prefix=prefix, vocab_size=VOCAB,\n",
    "        bos_id=BOS, eos_id=EOS, pad_id=PAD, unk_id=UNK,\n",
    "    )\n",
    "    return spm.SentencePieceProcessor(model_file=prefix+\".model\")\n",
    "\n",
    "ru_sp = train_spm('spm_ru', ['opus.en-ru-train.ru'])\n",
    "en_sp = train_spm('spm_en', ['opus.en-ru-train.en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153e7884-26b0-4f4a-b22a-db9f0108c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parallel(torch.utils.data.Dataset):\n",
    "    def __init__(self, src_path, tgt_path):\n",
    "        with open(src_path, encoding='utf-8') as fs, open(tgt_path, encoding='utf-8') as ft:\n",
    "            self.src, self.tgt = fs.readlines(), ft.readlines()\n",
    "    def __len__(self): return len(self.src)\n",
    "    def __getitem__(self, i): return self.src[i].rstrip(), self.tgt[i].rstrip()\n",
    "\n",
    "def collate(batch):\n",
    "    src_ids = [torch.tensor(ru_sp.encode(x),  dtype=torch.long) for x,_ in batch]\n",
    "    tgt_ids = [torch.tensor([BOS,*en_sp.encode(y),EOS], dtype=torch.long) for _,y in batch]\n",
    "    \n",
    "    return pad_sequence(src_ids, batch_first=False, padding_value=PAD), pad_sequence(tgt_ids, batch_first=False, padding_value=PAD)\n",
    "\n",
    "full_train = Parallel('opus.en-ru-train.ru','opus.en-ru-train.en')\n",
    "small_train = torch.utils.data.Subset(full_train, range(500))\n",
    "\n",
    "train_dl = DataLoader(small_train, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "valid_dl = DataLoader(Parallel('opus.en-ru-test.ru','opus.en-ru-test.en'), batch_size=64, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd1319e-45ae-42b3-b508-35a834189c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "class PosEnc(nn.Module):\n",
    "    def __init__(self, d, maxlen=5000):\n",
    "        super().__init__(); pe=torch.zeros(maxlen,d)\n",
    "        pos=torch.arange(0,maxlen).unsqueeze(1); den=torch.exp(-torch.arange(0,d,2)*math.log(10000)/d)\n",
    "        pe[:,0::2]=torch.sin(pos*den); pe[:,1::2]=torch.cos(pos*den)\n",
    "        self.register_buffer('pe',pe.unsqueeze(1))\n",
    "    def forward(self,x): return x+self.pe[:x.size(0)]\n",
    "\n",
    "class TransformerNMT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(ru_sp.get_piece_size(), EMB, PAD)\n",
    "        self.tgt_emb = nn.Embedding(en_sp.get_piece_size(), EMB, PAD)\n",
    "        self.pos     = PosEnc(EMB)\n",
    "        self.tr      = nn.Transformer(EMB, HEADS, LAYERS, LAYERS, FF, batch_first=False)\n",
    "        self.out     = nn.Linear(EMB, en_sp.get_piece_size())\n",
    "    def encode(self,src,mask):\n",
    "        return self.tr.encoder(self.pos(self.src_emb(src)), src_key_padding_mask=mask)\n",
    "    def decode(self,tgt,mem,src_mask,tgt_mask):\n",
    "        return self.tr.decoder(self.pos(self.tgt_emb(tgt)), mem, tgt_mask=tgt_mask, memory_key_padding_mask=src_mask)\n",
    "\n",
    "model = TransformerNMT().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optim   = torch.optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd7b2dc6-72ce-4f7a-b8d3-7e4321d95627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:03<00:00,  2.01it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:11<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train 8.481 | valid 8.418 | 15.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:02<00:00,  3.69it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:06<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train 8.227 | valid 8.271 | 8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:03<00:00,  2.34it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:04<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train 8.050 | valid 8.145 | 7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  4.00it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train 7.881 | valid 8.022 | 6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:01<00:00,  4.58it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:04<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train 7.723 | valid 7.906 | 6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SQM = lambda sz: torch.triu(torch.full((sz,sz),float('-inf')),1).to(device)\n",
    "\n",
    "def mask(mat): return (mat==PAD).T\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(train)\n",
    "    tot=0\n",
    "    steps=0\n",
    "    for src,tgt in tqdm(loader):\n",
    "        src,tgt = src.to(device), tgt.to(device)\n",
    "        tgt_in, tgt_out = tgt[:-1], tgt[1:]\n",
    "        mem = model.encode(src, mask(src))\n",
    "        dec = model.decode(tgt_in, mem, mask(src), SQM(tgt_in.size(0)))\n",
    "        logits = model.out(dec)\n",
    "        loss = loss_fn(logits.view(-1,logits.size(-1)), tgt_out.reshape(-1))\n",
    "        if train:\n",
    "            optim.zero_grad(); loss.backward(); optim.step()\n",
    "        tot+=loss.item(); steps+=1\n",
    "    return tot/steps\n",
    "\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    t0=time.time()\n",
    "    l_tr = run_epoch(train_dl,True)\n",
    "    l_va = run_epoch(valid_dl,False)\n",
    "    print(f\"Epoch {epoch}: train {l_tr:.3f} | valid {l_va:.3f} | {(time.time()-t0):.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a52276e0-6575-4c0a-8999-47d1b4c436ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def translate(texts, max_len=100):\n",
    "    src_ids=[torch.tensor(ru_sp.encode(t),dtype=torch.long) for t in texts]\n",
    "    src_pad = pad_sequence(src_ids, batch_first=False, padding_value=PAD).to(device)\n",
    "    mem=model.encode(src_pad,mask(src_pad))\n",
    "    B=len(texts); ys=torch.full((1,B),BOS,dtype=torch.long,device=device)\n",
    "    finished = torch.zeros((B,), dtype=torch.bool, device=device)\n",
    "    out=[[] for _ in texts]\n",
    "    for _ in range(max_len):\n",
    "        dec=model.decode(ys,mem,mask(src_pad),SQM(ys.size(0)))\n",
    "        nxt=model.out(dec[-1]).argmax(-1)\n",
    "        ys=torch.cat([ys,nxt.unsqueeze(0)],0)\n",
    "        finished|=(nxt==EOS)\n",
    "        for i,t in enumerate(nxt.tolist()):\n",
    "            if not finished[i]: out[i].append(t)\n",
    "        if finished.all(): break\n",
    "    return [en_sp.decode(o) for o in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd4d4d1c-a582-40db-b33d-8f2dc106446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample BLEU: 0.4548019047027907\n"
     ]
    }
   ],
   "source": [
    "hypothesis = ['It','is','a','cat','at','room']\n",
    "reference  = ['It','is','a','cat','inside','the','room']\n",
    "print('Sample BLEU:', nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, auto_reweigh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7a3704e-ee50-4592-936a-209041403144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU on 100 samples: 0.00\n",
      "\n",
      "RU: Выберите размер \n",
      "→  \n",
      "REF: Choose size M\n",
      "\n",
      "RU: Скажи (им) (о, Посланник): «Ведь я – человек, такой же, как вы. \n",
      "→  \n",
      "REF: Say (unto them O Muhammad): I am only a mortal like you.\n",
      "\n",
      "RU: Наибольшую озабоченность у пользователей вызывают проблемы увязки. \n",
      "→  \n",
      "REF: Linkage problems were the main user concern.\n",
      "\n",
      "RU: И именно на этой основе Конференция приняла мандат для специального комитета по ДЗПРМ, по пункту, который не получил упоминания в повестке дня, разве что в составе пункта 1 \"Прекращение гонки ядерных вооружений и ядерное разоружение\". \n",
      "→  \n",
      "REF: It is on this basis that the Conference adopted a mandate for an ad hoc committee on FMCT, an item which does not find mention on the agenda, except as part of item 1 - “Cessation of the nuclear arms race and nuclear disarmament”.\n",
      "\n",
      "RU: Из них есть такие, что ходят [ползают] на животе, и есть из них такие, что ходят на двух ногах [человек и птицы], и есть из них такие, что ходят на четырех. \n",
      "→  \n",
      "REF: Of them is (a kind) that goeth upon its belly and (a kind) that goeth upon two legs and (a kind) that goeth upon four.\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def sample_test(n=100):\n",
    "    test_ds = Parallel('opus.en-ru-test.ru','opus.en-ru-test.en')\n",
    "    idx=random.sample(range(len(test_ds)), n)\n",
    "    src=[test_ds[i][0] for i in idx]\n",
    "    ref=[test_ds[i][1] for i in idx]\n",
    "    hyp=translate(src)\n",
    "    refs=[[r.split()] for r in ref]\n",
    "    hyps=[h.split() for h in hyp]\n",
    "    score=nltk.translate.bleu_score.corpus_bleu(refs,hyps)\n",
    "    print(f'BLEU on {n} samples: {score*100:.2f}')\n",
    "    for s,h,r in list(zip(src,hyp,ref))[:5]:\n",
    "        print('\\nRU:',s,'\\n→',h,'\\nREF:',r)\n",
    "\n",
    "sample_test()\n",
    "\n",
    "# если учить большее число эпох, то будет нормально работать.... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa93d6",
   "metadata": {},
   "source": [
    "\n",
    "## Задание 2 (2 балла).\n",
    "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/13.pdf\n",
    "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как ее применить к паре en->ru на данных из семинара. Сколько моделей понадобится? Сколько запусков обучения нужно будет сделать?\n",
    "\n",
    "Ответ должен содержать как минимум 10 предложений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df3f6c-5615-4bc6-806b-68205aae239d",
   "metadata": {},
   "source": [
    "Техника back translation - техника улучшения качества машинного перевода, которая помогает расширить выборку путем генерации пар переводов при нехватке парных переводов. \n",
    "Эта техника заключается в следующем - мы берем текст на целевом языке, переводим его на исходный язык и затем создаем синтетическую пару, где предложение на одном языке сгенерировано, а на втором - нет.  Такие пары добавляются к набору и таким образом происходит расширение выборки.\n",
    "\n",
    "Для того, чтобы применить эту технику к паре языков ru<-en, нужно сделать следующее:\n",
    "\n",
    "1. Получить модель перевода с русского на английский (обучить или взять уе предобученную)\n",
    "2. Собрать корпус монолингвиальных русских предложений\n",
    "3. Пропустить русскоязычные предложения через модуль перевода с русского языка на английский, как итог получаем синтетические пары\n",
    "4. Объединяем синтетические пары и реальные\n",
    "5. Обучаем модель нужного нам перевода на объединенном корпусе\n",
    "\n",
    "В итоге нам понадобится две модели - модель перевода с русского на английский и с английского на русский.\n",
    "\n",
    "Если берется уже обученная модель для генерации синтетических текстов, то необходимое число запусков для обучения - 1, если ее необходимо обучить - 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005d3c9-d337-416d-b26c-446b3bae6824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
